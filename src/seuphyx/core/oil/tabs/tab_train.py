"""
Tab: æœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒï¼ˆä¸ªæ€§åŒ–ï¼‰
å…è®¸ç”¨æˆ·è‡ªå®šä¹‰é¢„å¤„ç†æ–¹å¼ã€é€‰æ‹©æ¨¡å‹ã€è®­ç»ƒå¹¶ä¿å­˜æ¨¡å‹
"""
# built-in
from pathlib import Path
from datetime import datetime

# third-party
import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
import plotly.io as pio
import joblib

# sklearn é¢„å¤„ç†
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler

# sklearn åˆ†ç±»æ¨¡å‹
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier

# sklearn èšç±»æ¨¡å‹
from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering

# sklearn è¯„ä¼°
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import (classification_report, confusion_matrix,
                             silhouette_score, calinski_harabasz_score,
                             davies_bouldin_score)

# sklearn æµæ°´çº¿
from sklearn.pipeline import make_pipeline

# seuphyx
from seuphyx.core.oil.utils import plotly_plot
import seuphyx


def render_tab_train():
    st.header("æœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒ")
    work_dir = st.session_state.work_dir

    # æŸ¥çœ‹å‚è€ƒæ•°æ®é›†
    data_dir = Path(seuphyx.__file__).parent / "data"
    model_file = data_dir / "points_svm_pipeline.joblib"
    model = joblib.load(model_file)
    reference_file = data_dir / "oil_drop_reference.csv"
    data_ref = pd.read_csv(reference_file)
    xy_coords = data_ref.values
    y_pred_ref = model.predict(xy_coords)
    data_ref_pred = pd.concat(
        [data_ref, pd.DataFrame({"Predicted": y_pred_ref})], axis=1)

    st.info("ğŸ“Š æœ¬é¡µé¢å…è®¸ä½ è‡ªå®šä¹‰é¢„å¤„ç†æ–¹å¼ã€é€‰æ‹©æ¨¡å‹ç±»å‹ï¼Œè®­ç»ƒå¹¶ä¿å­˜ä½ çš„ä¸ªæ€§åŒ–æ¨¡å‹ã€‚")

    # æ•°æ®é¢„è§ˆ
    with st.expander("æŸ¥çœ‹æ•°æ®é›†", expanded=False):
        st.dataframe(data_ref_pred, )
        st.markdown("""
            <style>
            [data-testid="stElementToolbar"] {
                display: none;
            }
            </style>
            """,
                    unsafe_allow_html=True)

    # ========== æ•°æ®é¢„å¤„ç†é€‰æ‹© ==========
    st.subheader("1ï¸âƒ£ æ•°æ®é¢„å¤„ç†")
    
    with st.expander("ğŸ’¡ ä»€ä¹ˆæ˜¯æ•°æ®é¢„å¤„ç†?", expanded=False):
        st.markdown("""
        æ•°æ®é¢„å¤„ç†æ˜¯æœºå™¨å­¦ä¹ æµç¨‹ä¸­çš„é‡è¦æ­¥éª¤,ç”¨äºå°†åŸå§‹æ•°æ®è½¬æ¢ä¸ºæ›´é€‚åˆæ¨¡å‹è®­ç»ƒçš„æ ¼å¼ã€‚
        ä¸åŒçš„é¢„å¤„ç†æ–¹æ³•é€‚ç”¨äºä¸åŒçš„åœºæ™¯:
        
        - **æ ‡å‡†åŒ– (StandardScaler)**: å°†æ•°æ®è½¬æ¢ä¸ºå‡å€¼ä¸º0ã€æ ‡å‡†å·®ä¸º1çš„åˆ†å¸ƒã€‚é€‚ç”¨äºå¤§å¤šæ•°æœºå™¨å­¦ä¹ ç®—æ³•ã€‚
          [ğŸ“– æ–‡æ¡£é“¾æ¥](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)
        
        - **å½’ä¸€åŒ– (MinMaxScaler)**: å°†æ•°æ®ç¼©æ”¾åˆ° [0, 1] åŒºé—´ã€‚é€‚ç”¨äºéœ€è¦å›ºå®šèŒƒå›´çš„åœºæ™¯ã€‚
          [ğŸ“– æ–‡æ¡£é“¾æ¥](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)
        
        - **é²æ£’ç¼©æ”¾ (RobustScaler)**: ä½¿ç”¨ä¸­ä½æ•°å’Œå››åˆ†ä½æ•°è¿›è¡Œç¼©æ”¾,å¯¹å¼‚å¸¸å€¼æ›´é²æ£’ã€‚
          [ğŸ“– æ–‡æ¡£é“¾æ¥](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html)
        """)

    preprocessing_options = st.multiselect("é€‰æ‹©é¢„å¤„ç†æ–¹æ³•ï¼ˆå¯å¤šé€‰ï¼‰",
                                           options=[
                                               "æ ‡å‡†åŒ– (StandardScaler)",
                                               "å½’ä¸€åŒ– (MinMaxScaler)",
                                               "é²æ£’ç¼©æ”¾ (RobustScaler)",
                                           ],
                                           placeholder="è‹¥æ— é€‰æ‹©åˆ™ä¸è¿›è¡Œé¢„å¤„ç†",
                                           default=[],
                                           help="ä¸åŒçš„é¢„å¤„ç†æ–¹æ³•ä¼šå½±å“æ¨¡å‹æ€§èƒ½")
    
    # æ˜¾ç¤ºé€‰ä¸­çš„é¢„å¤„ç†æ–¹æ³•è¯´æ˜
    if "æ ‡å‡†åŒ– (StandardScaler)" in preprocessing_options:
        st.info("âœ… **æ ‡å‡†åŒ–**: å°†æ•°æ®è½¬æ¢ä¸ºå‡å€¼0ã€æ ‡å‡†å·®1,å…¬å¼: $z = \\frac{x - \\mu}{\\sigma}$")
    if "å½’ä¸€åŒ– (MinMaxScaler)" in preprocessing_options:
        st.info("âœ… **å½’ä¸€åŒ–**: å°†æ•°æ®ç¼©æ”¾åˆ°[0,1],å…¬å¼: $x' = \\frac{x - x_{min}}{x_{max} - x_{min}}$")
    if "é²æ£’ç¼©æ”¾ (RobustScaler)" in preprocessing_options:
        st.info("âœ… **é²æ£’ç¼©æ”¾**: ä½¿ç”¨ä¸­ä½æ•°å’Œå››åˆ†ä½è·ç¼©æ”¾,å¯¹å¼‚å¸¸å€¼ä¸æ•æ„Ÿ")

    # é¢„å¤„ç†å‚æ•°é…ç½®
    preprocessing_params = {}

    # ========== æ¨¡å‹ç±»å‹é€‰æ‹© ==========
    st.subheader("2ï¸âƒ£ æ¨¡å‹é€‰æ‹©")

    model_type = st.radio(
        "é€‰æ‹©ä»»åŠ¡ç±»å‹",
        options=["åˆ†ç±»æ¨¡å‹", "èšç±»æ¨¡å‹"],
        horizontal=True,
    )

    selected_model = None
    model_params = {}
    if model_type == "åˆ†ç±»æ¨¡å‹":
        with st.expander("ğŸ’¡ ä»€ä¹ˆæ˜¯åˆ†ç±»æ¨¡å‹?", expanded=False):
            st.markdown("""
            **åˆ†ç±»æ¨¡å‹ (Classification)** æ˜¯ç›‘ç£å­¦ä¹ çš„ä¸€ç§,ç”¨äºå°†æ•°æ®ç‚¹åˆ†é…åˆ°é¢„å®šä¹‰çš„ç±»åˆ«ä¸­ã€‚
            
            - éœ€è¦**æ ‡æ³¨æ•°æ®**(å¸¦æœ‰ç±»åˆ«æ ‡ç­¾)è¿›è¡Œè®­ç»ƒ
            - é€‚ç”¨åœºæ™¯: é‚®ä»¶åˆ†ç±»(åƒåœ¾/æ­£å¸¸)ã€ç–¾ç—…è¯Šæ–­(æ‚£ç—…/å¥åº·)ã€å›¾åƒè¯†åˆ«ç­‰
            - è¯„ä¼°æŒ‡æ ‡: å‡†ç¡®ç‡ã€ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1åˆ†æ•°ç­‰
            
            [ğŸ“– sklearnåˆ†ç±»æ¨¡å‹æ€»è§ˆ](https://scikit-learn.org/stable/supervised_learning.html#supervised-learning)
            """)
        
        st.info("âš ï¸ åˆ†ç±»æ¨¡å‹éœ€è¦æ ‡æ³¨æ•°æ®ï¼Œå¦‚æœæ•°æ®æ²¡æœ‰æ ‡ç­¾ï¼Œè¯·å…ˆæ‰‹åŠ¨æ ‡æ³¨ã€‚")
        model_choice = st.selectbox("é€‰æ‹©åˆ†ç±»æ¨¡å‹",
                                    options=[
                                        "æ”¯æŒå‘é‡æœº (SVM)",
                                        "éšæœºæ£®æ— (Random Forest)",
                                        "æ¢¯åº¦æå‡ (Gradient Boosting)",
                                        "Kè¿‘é‚» (KNN)",
                                        "æœ´ç´ è´å¶æ–¯ (Naive Bayes)",
                                        "å†³ç­–æ ‘ (Decision Tree)",
                                    ])

        # æ¨¡å‹å‚æ•°é…ç½®
        st.write("âš™ï¸ æ¨¡å‹å‚æ•°é…ç½®")
        
        if model_choice == "æ”¯æŒå‘é‡æœº (SVM)":
            with st.expander("ğŸ“˜ SVM æ¨¡å‹è¯´æ˜", expanded=False):
                st.markdown("""
                **æ”¯æŒå‘é‡æœº (Support Vector Machine)** é€šè¿‡å¯»æ‰¾æœ€ä¼˜è¶…å¹³é¢æ¥åˆ†éš”ä¸åŒç±»åˆ«ã€‚
                
                - **ä¼˜ç‚¹**: åœ¨é«˜ç»´ç©ºé—´æœ‰æ•ˆ,å†…å­˜æ•ˆç‡é«˜,versatile(å¯ä½¿ç”¨ä¸åŒæ ¸å‡½æ•°)
                - **é€‚ç”¨åœºæ™¯**: æ–‡æœ¬åˆ†ç±»ã€å›¾åƒè¯†åˆ«ã€ç”Ÿç‰©ä¿¡æ¯å­¦
                - **å…³é”®å‚æ•°**:
                  - `C`: æ­£åˆ™åŒ–å‚æ•°,å€¼è¶Šå¤§è¶Šä¸å®¹æ˜“è¿‡æ‹Ÿåˆ
                  - `kernel`: æ ¸å‡½æ•°ç±»å‹(rbfé€‚åˆéçº¿æ€§,linearé€‚åˆçº¿æ€§å¯åˆ†)
                  - `gamma`: æ ¸å‡½æ•°ç³»æ•°,å½±å“å•ä¸ªæ ·æœ¬çš„å½±å“èŒƒå›´
                
                [ğŸ“– sklearn.svm.SVC æ–‡æ¡£](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)
                """)
            
            col1, col2 = st.columns(2)
            with col1:
                C = st.slider("C (æ­£åˆ™åŒ–å‚æ•°)", 0.01, 10.0, 1.0, 0.1)
                kernel = st.selectbox("æ ¸å‡½æ•°", ["rbf", "linear", "poly"])
            with col2:
                gamma = st.selectbox("gamma", ["scale", "auto"])
            model_params = {"C": C, "kernel": kernel, "gamma": gamma}
            selected_model = SVC(**model_params)

        elif model_choice == "éšæœºæ£®æ— (Random Forest)":
            with st.expander("ğŸ“˜ éšæœºæ£®æ—æ¨¡å‹è¯´æ˜", expanded=False):
                st.markdown("""
                **éšæœºæ£®æ— (Random Forest)** æ˜¯é›†æˆå­¦ä¹ æ–¹æ³•,é€šè¿‡æ„å»ºå¤šæ£µå†³ç­–æ ‘å¹¶æŠ•ç¥¨å¾—å‡ºç»“æœã€‚
                
                - **ä¼˜ç‚¹**: å‡†ç¡®ç‡é«˜,æŠ—è¿‡æ‹Ÿåˆèƒ½åŠ›å¼º,å¯ä»¥å¤„ç†é«˜ç»´æ•°æ®
                - **é€‚ç”¨åœºæ™¯**: ç‰¹å¾é‡è¦æ€§åˆ†æã€åˆ†ç±»å’Œå›å½’ä»»åŠ¡
                - **å…³é”®å‚æ•°**:
                  - `n_estimators`: æ£®æ—ä¸­æ ‘çš„æ•°é‡,è¶Šå¤šè¶Šå¥½ä½†è®¡ç®—æˆæœ¬å¢åŠ 
                  - `max_depth`: æ ‘çš„æœ€å¤§æ·±åº¦,æ§åˆ¶æ¨¡å‹å¤æ‚åº¦
                  - `min_samples_split`: èŠ‚ç‚¹åˆ†è£‚æ‰€éœ€çš„æœ€å°æ ·æœ¬æ•°
                
                [ğŸ“– sklearn.ensemble.RandomForestClassifier æ–‡æ¡£](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)
                """)
            
            col1, col2 = st.columns(2)
            with col1:
                n_estimators = st.slider("æ ‘çš„æ•°é‡", 10, 200, 100, 10)
                max_depth = st.slider("æœ€å¤§æ·±åº¦", 1, 20, 10)
            with col2:
                min_samples_split = st.slider("æœ€å°åˆ†è£‚æ ·æœ¬æ•°", 2, 20, 2)
            model_params = {
                "n_estimators": n_estimators,
                "max_depth": max_depth,
                "min_samples_split": min_samples_split,
                "criterion": "gini",  # Default value for criterion
                "bootstrap": True,  # Default value for bootstrap
                "oob_score": False,  # Default value for oob_score
                "warm_start": False,  # Default value for warm_start
                "class_weight": None,  # Default value for class_weight
                "random_state": 42
            }
            selected_model = RandomForestClassifier(**model_params)

        elif model_choice == "æ¢¯åº¦æå‡ (Gradient Boosting)":
            with st.expander("ğŸ“˜ æ¢¯åº¦æå‡æ¨¡å‹è¯´æ˜", expanded=False):
                st.markdown("""
                **æ¢¯åº¦æå‡ (Gradient Boosting)** é€šè¿‡é¡ºåºæ„å»ºå¼±å­¦ä¹ å™¨,æ¯ä¸ªæ–°æ ‘éƒ½çº æ­£å‰é¢æ ‘çš„é”™è¯¯ã€‚
                
                - **ä¼˜ç‚¹**: é¢„æµ‹ç²¾åº¦é«˜,å¯ä»¥å¤„ç†å„ç§ç±»å‹çš„æ•°æ®
                - **é€‚ç”¨åœºæ™¯**: Kaggleç«èµ›ã€éœ€è¦é«˜ç²¾åº¦çš„åˆ†ç±»ä»»åŠ¡
                - **å…³é”®å‚æ•°**:
                  - `n_estimators`: è¿­ä»£æ¬¡æ•°(æ ‘çš„æ•°é‡)
                  - `learning_rate`: å­¦ä¹ ç‡,æ§åˆ¶æ¯æ£µæ ‘çš„è´¡çŒ®
                  - `max_depth`: å•æ£µæ ‘çš„æœ€å¤§æ·±åº¦
                
                [ğŸ“– sklearn.ensemble.GradientBoostingClassifier æ–‡æ¡£](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)
                """)
            
            col1, col2 = st.columns(2)
            with col1:
                n_estimators = st.slider("è¿­ä»£æ¬¡æ•°", 10, 200, 100, 10)
                learning_rate = st.slider("å­¦ä¹ ç‡", 0.01, 1.0, 0.1, 0.01)
            with col2:
                max_depth = st.slider("æœ€å¤§æ·±åº¦", 1, 10, 3)
            model_params = {
                "n_estimators": n_estimators,
                "learning_rate": learning_rate,
                "max_depth": max_depth,
                "random_state": 42
            }
            selected_model = GradientBoostingClassifier(**model_params)

        elif model_choice == "Kè¿‘é‚» (KNN)":
            with st.expander("ğŸ“˜ Kè¿‘é‚»æ¨¡å‹è¯´æ˜", expanded=False):
                st.markdown("""
                **Kè¿‘é‚» (K-Nearest Neighbors)** é€šè¿‡å¯»æ‰¾æœ€è¿‘çš„Kä¸ªé‚»å±…è¿›è¡ŒæŠ•ç¥¨åˆ†ç±»ã€‚
                
                - **ä¼˜ç‚¹**: ç®€å•ç›´è§‚,æ— éœ€è®­ç»ƒè¿‡ç¨‹,é€‚åˆå¤šåˆ†ç±»é—®é¢˜
                - **é€‚ç”¨åœºæ™¯**: æ¨èç³»ç»Ÿã€æ¨¡å¼è¯†åˆ«ã€å¼‚å¸¸æ£€æµ‹
                - **å…³é”®å‚æ•°**:
                  - `n_neighbors`: Kå€¼,é‚»å±…æ•°é‡
                  - `weights`: æƒé‡å‡½æ•°(uniformç»Ÿä¸€æƒé‡,distanceè·ç¦»åŠ æƒ)
                  - `metric`: è·ç¦»åº¦é‡æ–¹å¼
                
                [ğŸ“– sklearn.neighbors.KNeighborsClassifier æ–‡æ¡£](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)
                """)
            
            col1, col2 = st.columns(2)
            with col1:
                n_neighbors = st.slider("é‚»å±…æ•°é‡ (K)", 1, 20, 5)
                weights = st.selectbox("æƒé‡", ["uniform", "distance"])
            with col2:
                metric = st.selectbox("è·ç¦»åº¦é‡",
                                      ["euclidean", "manhattan", "minkowski"])
            model_params = {
                "n_neighbors": n_neighbors,
                "weights": weights,
                "metric": metric
            }
            selected_model = KNeighborsClassifier(**model_params)

        elif model_choice == "æœ´ç´ è´å¶æ–¯ (Naive Bayes)":
            with st.expander("ğŸ“˜ æœ´ç´ è´å¶æ–¯æ¨¡å‹è¯´æ˜", expanded=False):
                st.markdown("""
                **æœ´ç´ è´å¶æ–¯ (Naive Bayes)** åŸºäºè´å¶æ–¯å®šç†å’Œç‰¹å¾ç‹¬ç«‹å‡è®¾çš„æ¦‚ç‡åˆ†ç±»å™¨ã€‚
                
                - **ä¼˜ç‚¹**: è®­ç»ƒé€Ÿåº¦å¿«,å¯¹å°è§„æ¨¡æ•°æ®è¡¨ç°å¥½,é€‚åˆå¤šåˆ†ç±»
                - **é€‚ç”¨åœºæ™¯**: æ–‡æœ¬åˆ†ç±»ã€åƒåœ¾é‚®ä»¶è¿‡æ»¤ã€æƒ…æ„Ÿåˆ†æ
                - **ç‰¹ç‚¹**: å‡è®¾ç‰¹å¾ä¹‹é—´ç›¸äº’ç‹¬ç«‹
                
                [ğŸ“– sklearn.naive_bayes.GaussianNB æ–‡æ¡£](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)
                """)
            st.info("âœ… æœ´ç´ è´å¶æ–¯æ¨¡å‹ä½¿ç”¨é»˜è®¤å‚æ•°")
            selected_model = GaussianNB()

        elif model_choice == "å†³ç­–æ ‘ (Decision Tree)":
            with st.expander("ğŸ“˜ å†³ç­–æ ‘æ¨¡å‹è¯´æ˜", expanded=False):
                st.markdown("""
                **å†³ç­–æ ‘ (Decision Tree)** é€šè¿‡æ ‘çŠ¶ç»“æ„è¿›è¡Œå†³ç­–,æ¯ä¸ªèŠ‚ç‚¹ä»£è¡¨ä¸€ä¸ªç‰¹å¾åˆ¤æ–­ã€‚
                
                - **ä¼˜ç‚¹**: æ˜“äºç†è§£å’Œè§£é‡Š,å¯è§†åŒ–ç›´è§‚,ä¸éœ€è¦æ•°æ®å½’ä¸€åŒ–
                - **é€‚ç”¨åœºæ™¯**: è§„åˆ™æå–ã€ç‰¹å¾é€‰æ‹©ã€å¯è§£é‡Šæ€§è¦æ±‚é«˜çš„åœºæ™¯
                - **å…³é”®å‚æ•°**:
                  - `max_depth`: æ ‘çš„æœ€å¤§æ·±åº¦,é˜²æ­¢è¿‡æ‹Ÿåˆ
                  - `min_samples_split`: èŠ‚ç‚¹åˆ†è£‚æ‰€éœ€çš„æœ€å°æ ·æœ¬æ•°
                  - `criterion`: åˆ†è£‚æ ‡å‡†(giniåŸºå°¼ç³»æ•°,entropyä¿¡æ¯ç†µ)
                
                [ğŸ“– sklearn.tree.DecisionTreeClassifier æ–‡æ¡£](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)
                """)
            
            col1, col2 = st.columns(2)
            with col1:
                max_depth = st.slider("æœ€å¤§æ·±åº¦", 1, 20, 10)
                min_samples_split = st.slider("æœ€å°åˆ†è£‚æ ·æœ¬æ•°", 2, 20, 2)
            with col2:
                criterion = st.selectbox("åˆ†è£‚æ ‡å‡†", ["gini", "entropy"])
            model_params = {
                "max_depth": max_depth,
                "min_samples_split": min_samples_split,
                "criterion": criterion,
                "random_state": 42
            }
            selected_model = DecisionTreeClassifier(**model_params)

    else:  # èšç±»æ¨¡å‹
        with st.expander("ğŸ’¡ ä»€ä¹ˆæ˜¯èšç±»æ¨¡å‹?", expanded=False):
            st.markdown("""
            **èšç±»æ¨¡å‹ (Clustering)** æ˜¯æ— ç›‘ç£å­¦ä¹ çš„ä¸€ç§,ç”¨äºå‘ç°æ•°æ®ä¸­çš„è‡ªç„¶åˆ†ç»„ã€‚
            
            - ä¸éœ€è¦**æ ‡æ³¨æ•°æ®**,è‡ªåŠ¨å‘ç°æ•°æ®æ¨¡å¼
            - é€‚ç”¨åœºæ™¯: å®¢æˆ·ç»†åˆ†ã€å›¾åƒåˆ†å‰²ã€å¼‚å¸¸æ£€æµ‹ã€æ•°æ®æ¢ç´¢
            - è¯„ä¼°æŒ‡æ ‡: è½®å»“ç³»æ•°ã€Calinski-HarabaszæŒ‡æ•°ã€Davies-BouldinæŒ‡æ•°
            
            [ğŸ“– sklearnèšç±»æ¨¡å‹æ€»è§ˆ](https://scikit-learn.org/stable/modules/clustering.html)
            """)
        
        st.info("âœ… èšç±»æ¨¡å‹ä¸éœ€è¦æ ‡ç­¾,è‡ªåŠ¨å‘ç°æ•°æ®ä¸­çš„æ¨¡å¼ã€‚")
        model_choice = st.selectbox("é€‰æ‹©èšç±»æ¨¡å‹",
                                    options=[
                                        "K-Means",
                                        "DBSCAN",
                                        "å±‚æ¬¡èšç±» (Agglomerative)",
                                    ])

        st.write("âš™ï¸ æ¨¡å‹å‚æ•°é…ç½®")

        if model_choice == "K-Means":
            with st.expander("ğŸ“˜ K-Means æ¨¡å‹è¯´æ˜", expanded=False):
                st.markdown("""
                **K-Means** å°†æ•°æ®åˆ’åˆ†ä¸ºKä¸ªç°‡,æ¯ä¸ªç‚¹å±äºè·ç¦»æœ€è¿‘çš„èšç±»ä¸­å¿ƒã€‚
                
                - **ä¼˜ç‚¹**: ç®€å•å¿«é€Ÿ,é€‚åˆå¤§è§„æ¨¡æ•°æ®,å¯æ‰©å±•æ€§å¥½
                - **é€‚ç”¨åœºæ™¯**: å®¢æˆ·ç»†åˆ†ã€å›¾åƒå‹ç¼©ã€æ–‡æ¡£èšç±»
                - **å…³é”®å‚æ•°**:
                  - `n_clusters`: èšç±»æ•°é‡K,éœ€è¦é¢„å…ˆæŒ‡å®š
                  - `max_iter`: æœ€å¤§è¿­ä»£æ¬¡æ•°
                  - `init`: åˆå§‹åŒ–æ–¹æ³•(k-means++æ›´æ™ºèƒ½)
                
                [ğŸ“– sklearn.cluster.KMeans æ–‡æ¡£](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)
                """)
            
            col1, col2 = st.columns(2)
            with col1:
                n_clusters = st.slider("èšç±»æ•°é‡", 2, 10, 3)
                max_iter = st.slider("æœ€å¤§è¿­ä»£æ¬¡æ•°", 100, 1000, 300, 100)
            with col2:
                init = st.selectbox("åˆå§‹åŒ–æ–¹æ³•", ["k-means++", "random"])
            model_params = {
                "n_clusters": n_clusters,
                "max_iter": max_iter,
                "init": init,
                "random_state": 42
            }
            selected_model = KMeans(**model_params)

        elif model_choice == "DBSCAN":
            with st.expander("ğŸ“˜ DBSCAN æ¨¡å‹è¯´æ˜", expanded=False):
                st.markdown("""
                **DBSCAN (Density-Based Spatial Clustering)** åŸºäºå¯†åº¦çš„èšç±»ç®—æ³•ã€‚
                
                - **ä¼˜ç‚¹**: ä¸éœ€è¦é¢„å…ˆæŒ‡å®šèšç±»æ•°,å¯ä»¥å‘ç°ä»»æ„å½¢çŠ¶çš„ç°‡,èƒ½è¯†åˆ«å™ªå£°ç‚¹
                - **é€‚ç”¨åœºæ™¯**: åœ°ç†æ•°æ®èšç±»ã€å¼‚å¸¸æ£€æµ‹ã€ä¸è§„åˆ™å½¢çŠ¶ç°‡
                - **å…³é”®å‚æ•°**:
                  - `eps`: é‚»åŸŸåŠå¾„,å®šä¹‰"é‚»è¿‘"çš„è·ç¦»
                  - `min_samples`: æ ¸å¿ƒç‚¹æ‰€éœ€çš„æœ€å°é‚»å±…æ•°
                  - `metric`: è·ç¦»åº¦é‡æ–¹å¼
                
                [ğŸ“– sklearn.cluster.DBSCAN æ–‡æ¡£](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html)
                """)
            
            col1, col2 = st.columns(2)
            with col1:
                eps = st.slider("é‚»åŸŸåŠå¾„ (eps)", 0.1, 10.0, 0.5, 0.1)
                min_samples = st.slider("æœ€å°æ ·æœ¬æ•°", 1, 20, 5)
            with col2:
                metric = st.selectbox("è·ç¦»åº¦é‡",
                                      ["euclidean", "manhattan", "cosine"])
            model_params = {
                "eps": eps,
                "min_samples": min_samples,
                "metric": metric
            }
            selected_model = DBSCAN(**model_params)

        elif model_choice == "å±‚æ¬¡èšç±» (Agglomerative)":
            with st.expander("ğŸ“˜ å±‚æ¬¡èšç±»æ¨¡å‹è¯´æ˜", expanded=False):
                st.markdown("""
                **å±‚æ¬¡èšç±» (Agglomerative Clustering)** é€šè¿‡è‡ªåº•å‘ä¸Šçš„æ–¹å¼æ„å»ºèšç±»æ ‘ã€‚
                
                - **ä¼˜ç‚¹**: ä¸éœ€è¦é¢„å…ˆæŒ‡å®šç°‡æ•°,å¯ä»¥ç”Ÿæˆèšç±»æ ‘çŠ¶å›¾(dendrogram)
                - **é€‚ç”¨åœºæ™¯**: ç”Ÿç‰©ä¿¡æ¯å­¦ã€ç¤¾äº¤ç½‘ç»œåˆ†æã€æ–‡æ¡£å±‚æ¬¡åˆ†ç±»
                - **å…³é”®å‚æ•°**:
                  - `n_clusters`: èšç±»æ•°é‡
                  - `linkage`: é“¾æ¥æ–¹å¼(wardæœ€å°åŒ–æ–¹å·®,completeæœ€å¤§è·ç¦»,averageå¹³å‡è·ç¦»)
                  - `metric`: è·ç¦»åº¦é‡(wardåªèƒ½ç”¨euclidean)
                
                [ğŸ“– sklearn.cluster.AgglomerativeClustering æ–‡æ¡£](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html)
                """)
            
            col1, col2 = st.columns(2)
            with col1:
                n_clusters = st.slider("èšç±»æ•°é‡", 2, 10, 3)
                linkage = st.selectbox(
                    "é“¾æ¥æ–¹æ³•", ["ward", "complete", "average", "single"])
            with col2:
                metric = st.selectbox("è·ç¦»åº¦é‡",
                                      ["euclidean", "manhattan", "cosine"])
            model_params = {
                "n_clusters": n_clusters,
                "linkage": linkage,
            }
            if linkage != "ward":
                model_params["metric"] = metric
            selected_model = AgglomerativeClustering(**model_params)

    # ========== å¼€å§‹è®­ç»ƒ ==========
    st.subheader("3ï¸âƒ£ æ¨¡å‹è®­ç»ƒ")

    if st.button("å¼€å§‹è®­ç»ƒä¸ªäººçš„æ¨¡å‹", type="primary", use_container_width=True):
        with st.spinner("è®­ç»ƒä¸­ï¼Œè¯·ç¨å€™..."):
            try:
                # å‡†å¤‡æ•°æ®
                data_ref = data_ref_pred[[
                    'FallingTime(t/s)', 'BalanceVoltage(U/V)'
                ]].values
                data_ref = data_ref.copy()

                # æ•°æ®é¢„å¤„ç†
                scalers = []

                if "æ ‡å‡†åŒ– (StandardScaler)" in preprocessing_options:
                    scalers.append(('StandardScaler', StandardScaler()))

                if "å½’ä¸€åŒ– (MinMaxScaler)" in preprocessing_options:
                    scalers.append(('MinMaxScaler', MinMaxScaler()))

                if "é²æ£’ç¼©æ”¾ (RobustScaler)" in preprocessing_options:
                    scalers.append(('RobustScaler', RobustScaler()))

                # è®­ç»ƒæ¨¡å‹
                if model_type == "åˆ†ç±»æ¨¡å‹":
                    labels = data_ref_pred['Predicted'].values

                    # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
                    X_train, X_test, y_train, y_test = train_test_split(
                        data_ref, labels, test_size=0.2)

                    # è®­ç»ƒ
                    clf = make_pipeline(*[scaler for _, scaler in scalers],
                                        selected_model)
                    clf.fit(X_train, y_train)

                    # é¢„æµ‹
                    y_pred_train = clf.predict(X_train)
                    y_pred_test = clf.predict(X_test)
                    y_pred_all = clf.predict(data_ref)

                    # è¯„ä¼°
                    train_score = clf.score(X_train, y_train)
                    test_score = clf.score(X_test, y_test)

                    # äº¤å‰éªŒè¯
                    cv_scores = cross_val_score(
                        clf,
                        data_ref,
                        labels,  # type: ignore
                        cv=5,
                    )

                    # ä¿å­˜ç»“æœåˆ° session_state
                    st.session_state.trained_model = {
                        'model':
                        selected_model,
                        'model_type':
                        model_type,
                        'model_name':
                        model_choice,
                        'scalers':
                        scalers,
                        'X_processed':
                        data_ref,
                        'y_true':
                        labels,
                        'y_pred':
                        y_pred_all,
                        'train_score':
                        train_score,
                        'test_score':
                        test_score,
                        'cv_scores':
                        cv_scores,
                        'classification_report':
                        classification_report(y_test, y_pred_test),
                        'confusion_matrix':
                        confusion_matrix(y_test, y_pred_test),
                        'preprocessing_options':
                        preprocessing_options,
                        'model_params':
                        model_params,
                    }

                    st.success("âœ… åˆ†ç±»æ¨¡å‹è®­ç»ƒå®Œæˆï¼")

                else:  # èšç±»æ¨¡å‹
                    # è®­ç»ƒ
                    clf = make_pipeline(*[scaler for _, scaler in scalers],
                                        selected_model)
                    y_pred = clf.fit_predict(data_ref)

                    # è¯„ä¼°
                    silhouette = silhouette_score(data_ref, y_pred)
                    calinski = calinski_harabasz_score(data_ref, y_pred)
                    davies = davies_bouldin_score(data_ref, y_pred)

                    # ä¿å­˜ç»“æœ
                    st.session_state.trained_model = {
                        'model': selected_model,
                        'model_type': model_type,
                        'model_name': model_choice,
                        'scalers': scalers,
                        'X_processed': data_ref,
                        'y_pred': y_pred,
                        'silhouette_score': silhouette,
                        'calinski_score': calinski,
                        'davies_bouldin_score': davies,
                        'preprocessing_options': preprocessing_options,
                        'model_params': model_params,
                    }

                    st.success("âœ… èšç±»æ¨¡å‹è®­ç»ƒå®Œæˆï¼")

                st.session_state.clf = clf

            except Exception as e:
                st.error(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
                st.exception(e)

    # ========== æ˜¾ç¤ºè®­ç»ƒç»“æœ ==========
    if 'trained_model' in st.session_state:
        st.subheader("4ï¸âƒ£ è®­ç»ƒç»“æœ")

        result = st.session_state.trained_model

        # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
        with st.expander("ğŸ“ æ¨¡å‹é…ç½®ä¿¡æ¯", expanded=False):
            st.write(f"**æ¨¡å‹ç±»å‹**: {result['model_type']}")
            st.write(f"**æ¨¡å‹åç§°**: {result['model_name']}")
            ppopt = result['preprocessing_options']
            ppopt = ', '.join(ppopt) if ppopt else 'æ— '
            st.write(f"**é¢„å¤„ç†æ–¹æ³•**: {ppopt}")
            st.write(f"**æ¨¡å‹å‚æ•°**: {result['model_params']}")

        # æ€§èƒ½æŒ‡æ ‡
        st.write("### ğŸ“Š æ€§èƒ½æŒ‡æ ‡")

        if result['model_type'] == "åˆ†ç±»æ¨¡å‹":
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("è®­ç»ƒé›†å‡†ç¡®ç‡", f"{result['train_score']*100:.1f}%")
            with col2:
                st.metric("æµ‹è¯•é›†å‡†ç¡®ç‡", f"{result['test_score']*100:.1f}%")
            with col3:
                st.metric("äº¤å‰éªŒè¯å‡å€¼", f"{result['cv_scores'].mean()*100:.1f}%")

            # æ··æ·†çŸ©é˜µ
            st.subheader("æ··æ·†çŸ©é˜µ")
            fig_cm = go.Figure(
                data=go.Heatmap(z=result['confusion_matrix'],
                                colorscale='Blues',
                                text=result['confusion_matrix'],
                                texttemplate="%{text}",
                                textfont={"size": 18}),
                layout=go.Layout(
                    title="æ··æ·†çŸ©é˜µ",
                    xaxis=dict(title="é¢„æµ‹ç±»åˆ«"),
                    yaxis=dict(title="çœŸå®ç±»åˆ«"),
                    font=dict(family='DejaVu Serif', size=16),
                    margin=dict(l=60, r=30, t=30, b=60),
                    colorway=px.colors.qualitative.D3,
                    height=400,
                ),
            )
            st.plotly_chart(fig_cm, use_container_width=True)

        else:  # èšç±»æ¨¡å‹
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("è½®å»“ç³»æ•°",
                          f"{result['silhouette_score']:.4f}",
                          help="èŒƒå›´[-1,1]ï¼Œè¶Šæ¥è¿‘1è¶Šå¥½")
            with col2:
                st.metric("Calinski-HarabaszæŒ‡æ•°",
                          f"{result['calinski_score']:.2f}",
                          help="å€¼è¶Šå¤§è¶Šå¥½")
            with col3:
                st.metric("Davies-BouldinæŒ‡æ•°",
                          f"{result['davies_bouldin_score']:.4f}",
                          help="å€¼è¶Šå°è¶Šå¥½")

        # å¯è§†åŒ–ç»“æœ
        st.write("### ğŸ“ˆ ç»“æœå¯è§†åŒ–")

        # å‡†å¤‡ç»˜å›¾æ•°æ®
        X_plot = result['X_processed']
        y_plot = result['y_pred']

        # å¦‚æœç»´åº¦å¤§äº2ï¼Œåªå–å‰ä¸¤ç»´
        if X_plot.shape[1] > 2:
            X_plot = X_plot[:, :2]
            st.info("æ³¨æ„ï¼šæ•°æ®ç»´åº¦>2ï¼Œä»…æ˜¾ç¤ºå‰ä¸¤ä¸ªç»´åº¦")

        # åˆ›å»ºæ•£ç‚¹å›¾
        unique_labels = np.unique(y_plot)
        fig = go.Figure()

        for label in unique_labels:
            mask = y_plot == label
            fig.add_trace(
                go.Scatter(x=X_plot[mask, 0],
                           y=X_plot[mask, 1],
                           mode='markers',
                           name=f'ç±»åˆ« {label}',
                           marker=dict(size=10,
                                       line=dict(width=1, color='white'))))

        fig.update_layout(
            title=f"{result['model_name']} - èšç±»/åˆ†ç±»ç»“æœ",
            xaxis_title="ç‰¹å¾1"
            if "PCAé™ç»´" in result['preprocessing_options'] else "ä¸‹è½æ—¶é—´ (t/s)",
            yaxis_title="ç‰¹å¾2"
            if "PCAé™ç»´" in result['preprocessing_options'] else "å¹³è¡¡ç”µå‹ (U/V)",
            font=dict(size=14),
            height=500,
            margin=dict(l=60, r=30, t=60, b=60),
            colorway=px.colors.qualitative.D3,
        )

        st.plotly_chart(fig, use_container_width=True)

        # ========== ä¿å­˜æ¨¡å‹ ==========
        st.subheader("5ï¸âƒ£ ä¿å­˜æ¨¡å‹")

        # è·å–å·²æœ‰æ¨¡å‹æ•°é‡
        existing_models = list(
            work_dir.glob(f"{result['model_name'].replace(' ', '_')}*.joblib"))
        next_number = len(existing_models) + 1

        default_filename = f"{result['model_name'].replace(' ', '_').replace('(', '').replace(')', '')}_{next_number:03d}.joblib"

        col1, col2 = st.columns([5, 1])
        with col1:
            model_filename = st.text_input("æ¨¡å‹æ–‡ä»¶å",
                                           value=default_filename,
                                           help="æ¨¡å‹å°†ä¿å­˜ä¸º .joblib æ ¼å¼")

        with col2:
            st.write("")
            st.write("")
            if st.button("ä¿å­˜æ¨¡å‹", type="primary"):
                try:
                    joblib.dump(st.session_state.clf,
                                work_dir / model_filename)
                except Exception as e:
                    st.error(f"ä¿å­˜å¤±è´¥: {e}")

        # æ˜¾ç¤ºå·²ä¿å­˜çš„æ¨¡å‹
        with st.expander("ğŸ“‚ æŸ¥çœ‹å·²ä¿å­˜çš„æ¨¡å‹"):
            saved_models = sorted(work_dir.glob("*.joblib"))
            if saved_models:
                st.write(f"å…± {len(saved_models)} ä¸ªå·²ä¿å­˜æ¨¡å‹ï¼š")
                for model_path in saved_models:
                    st.write(f"- {model_path.name}")
            else:
                st.write("æš‚æ— å·²ä¿å­˜çš„æ¨¡å‹")
